2017年CCF-AI法官大赛(http://www.datafountain.cn/#/competitions/277/intro)源码

获得第9名(9/415)


主要步骤：

1、分词 

分词我们用的jieba，中间尝试了Stanford分词和哈工大分词，对于结果没有什么差别，有的nlp比赛经验说用不同分词结果做数据扩充结果会有一点提升，但是对于这个比赛并没有起到作用

2、去除停用词
简单的去除了一些汉语标点和“的”这种语义助词，其他的词全部保留，因为案件和条文的用语非常规范，去除太多的词反而会影响效果

3、数据的填充、过滤、删除
中间会有一些数据全部字数少于5个字，或者全英文结果，需要去除一下


4、特征提取

5、训练与模型
题目要求对于每一个案件都给出判决犯了417条法律中的哪一条，8种罚金额度的哪一种，所以我们的初步思路是对于417条法律，每一条都训练一个模型，涉及到该条法律的案件作为正样例，不涉及该条法律的案件作为负样例，对于每条法律，每种罚金都训练一个二分类模型；

虽然说每种法律都有可能性，但是有10条法律出现在95%以上的样例中，剩下的法律条文的数据条数非常少，所以对于那部分的样例训练出的结果极不稳定，我们选择只对那10条法律，8中罚金，每一个都训练二分类模型；

模型上我们尝试了TFIDF+NaiveBayes（getTFIDF.py），word2vec+xgboost,wordbag+xgboost，cnn_feature+xgboost(getfeature.py+cnn_money.py)；
发现wordbag+xgboost(getxgboostwordbagjin2.py)
6、模型融合
